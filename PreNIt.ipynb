{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fb6211",
   "metadata": {},
   "source": [
    "# Item_based collaborative ranking\n",
    "\n",
    "<span style=\"color:pink; font-size:20px \">Implemented by Malihe Ghazalian</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1b60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "from networkx.algorithms import bipartite\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da963c7",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15361286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ratings data from Movielense 100k\n",
    "rating_columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratingData = pd.read_csv('../Movielense100k/ml-100k/u.data', sep='\\t', names=rating_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f93c4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratingData['user_id'].max()\n",
    "num_movies = ratingData['movie_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of users: \", num_users, \"\\n\")\n",
    "print(\"Number of movies: \", num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratingData.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c309559",
   "metadata": {},
   "source": [
    "## Create Pairwise preference dataset\n",
    "We need to create pairwise preference dataset out of Movielense 100k rating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b887eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating = ratingData.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a0cde4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_rating = {}\n",
    "test_user_rating = {}\n",
    "values = [10, 20, 30, 40]\n",
    "\n",
    "# Assuming user_rating is a dictionary where keys are user IDs\n",
    "for uid, urates in user_rating:\n",
    "    random_value = random.choice(values)\n",
    "    train_user_rating[uid] = {}\n",
    "    test_user_rating[uid] = {}\n",
    "    \n",
    "    if len(urates) > 10:\n",
    "        # Sample a random value \n",
    "        random_value = min(random_value, len(urates))\n",
    "        \n",
    "        train_ratings = urates.sample(n=random_value)\n",
    "        test_ratings = urates.drop(train_ratings.index)\n",
    "    \n",
    "        # Assign ratings to the training set\n",
    "        for index, row in train_ratings.iterrows():\n",
    "            train_user_rating[uid][row['movie_id']] = row['rating']\n",
    "            \n",
    "        # Assign ratings to the test set\n",
    "        for index, row in test_ratings.iterrows():\n",
    "            test_user_rating[uid][row['movie_id']] = row['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a905f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate pairwise preferences for a user\n",
    "def generate_pairwise_preferences_for_user(user_id, user_ratings):\n",
    "    pairwise_preferences = []\n",
    "    for movie_id1, rating1 in user_ratings.items():\n",
    "        for movie_id2, rating2 in user_ratings.items():\n",
    "            if movie_id1 != movie_id2:\n",
    "                preference = 1 if rating1 > rating2 else None\n",
    "                if preference:\n",
    "                    pairwise_preferences.append((user_id, movie_id1, movie_id2))\n",
    "    return pairwise_preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304dab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairwise_preferences = []\n",
    "# test_pairwise_preferences = []\n",
    "for uid, user_rates in train_user_rating.items():\n",
    "    pairwise_preferences = generate_pairwise_preferences_for_user(uid, user_rates)\n",
    "    train_pairwise_preferences.extend(pairwise_preferences)\n",
    "    \n",
    "    print(\"done for user \", uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd37abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and save or further process as needed\n",
    "train_pairwise_df = pd.DataFrame(train_pairwise_preferences, columns=['user_id', 'wining_item', 'losing_item'])\n",
    "# test_pairwise_df = pd.DataFrame(test_pairwise_preferences, columns=['user_id', 'wining_item', 'losing_item'])\n",
    "train_pairwise_df.to_csv('../Movielense100k//ml-100k/pairwise_preferences.csv', index=False)\n",
    "# test_pairwise_df.to_csv('../Movielense100k//ml-100k/pairwise_preferences.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45bfa7c",
   "metadata": {},
   "source": [
    "## Network Construction\n",
    "<div style=\"font-size: \"> our network contains 2 bipartite network which are LNet, WNet <div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882ec24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_preferences_dataset_names = ['user_id', 'wining_item', 'losing_item']\n",
    "train_pairwise_data = pd.read_csv('../Movielense100k/ml-100k/pairwise_preferences.csv')\n",
    "# test_pairwise_data = pd.read_csv('../Movielense100k/ml-100k/test_pairwise_preferences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e96f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairwise_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efac1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_pairwise_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_pairwise_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db104ba6",
   "metadata": {},
   "source": [
    "#### ADD Edges for creating networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7eb569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Edges\n",
    "Ew = []\n",
    "El = []\n",
    "users = set()\n",
    "win_items = set()\n",
    "lose_items = set()\n",
    "\n",
    "for item in train_pairwise_data.values:\n",
    "    user_id = item[0]\n",
    "    prefered = item[1]\n",
    "    notPrefered = item[2]\n",
    "\n",
    "    # Append edge and update sets of users and movies\n",
    "    Ew.append((str(user_id), prefered, {'label': notPrefered}))\n",
    "    El.append((str(user_id), notPrefered, {'label': prefered} ))\n",
    "    \n",
    "    users.add(str(user_id))\n",
    "    win_items.add(prefered)\n",
    "    lose_items.add(notPrefered)\n",
    "\n",
    "# Create a bipartite graph\n",
    "WNet = nx.Graph()\n",
    "LNet = nx.Graph()\n",
    "\n",
    "# Add nodes to WNet\n",
    "WNet.add_nodes_from(users, bipartite=0, type='user')  # Users\n",
    "WNet.add_nodes_from(win_items, bipartite=1, type='item')  # Winning items\n",
    "\n",
    "# Add nodes to LNet\n",
    "LNet.add_nodes_from(users, bipartite=0, type='user')  # Users\n",
    "LNet.add_nodes_from(lose_items, bipartite=1, type='item')  # Losing items\n",
    "\n",
    "# # Add edges\n",
    "WNet.add_edges_from(Ew)\n",
    "LNet.add_edges_from(El)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee944eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select a subset of users and movies for visualization\n",
    "subset_users = random.sample(list(users), k=10)  \n",
    "subset_movies = random.sample(list(win_items), k=10)  \n",
    "\n",
    "# Draw the bipartite graph\n",
    "pos = nx.bipartite_layout(WNet, subset_users)  \n",
    "\n",
    "# Draw nodes for the subset\n",
    "nx.draw_networkx_nodes(WNet, pos, nodelist=subset_users, node_color='b', alpha=0.5)  # Users\n",
    "nx.draw_networkx_nodes(WNet, pos, nodelist=subset_movies, node_color='r', alpha=0.5)  # Movies\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(WNet, pos)\n",
    "\n",
    "# Draw labels \n",
    "# nx.draw_networkx_labels(WNet, pos)\n",
    "\n",
    "# Show plot\n",
    "plt.title(\"Subset of WNet of Users and Movies\")\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e4933",
   "metadata": {},
   "source": [
    "#### Create Pu, Wu and Lu\n",
    "<div style = \"font: 20px; color: light-blue\"> We need to create a set of pairwise preference for each user and also create a set of winning items and set of lossing items based  on each user.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed2a7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "O = train_pairwise_data.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72ce0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairwise preferences group by users name it pu\n",
    "pu = {}\n",
    "for row in O:\n",
    "    user_id = row[0]\n",
    "    if user_id not in pu:\n",
    "        pu[user_id] = []\n",
    "    for pair_row in row[1].values:\n",
    "        pu[user_id].append(pair_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee8d95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wu = {}\n",
    "Lu = {}\n",
    "for row in O:\n",
    "    user_id = row[0]\n",
    "    winning_items = set()\n",
    "    losing_items = set()\n",
    "    \n",
    "    if user_id not in Wu:\n",
    "        Wu[user_id] = []\n",
    "        Lu[user_id] = []\n",
    "    for i in row[1].values:\n",
    "        _, winning_item, losing_item = i\n",
    "        winning_items.add(winning_item)\n",
    "        losing_items.add(losing_item)\n",
    "        \n",
    "    Wu[user_id].append(winning_items)\n",
    "    Lu[user_id].append(losing_items)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd15f8",
   "metadata": {},
   "source": [
    "# Create Algorithms to calculate item ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d126b9",
   "metadata": {},
   "source": [
    "##### PreNIt recomendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bee6d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateWinningFrequency(O, i):\n",
    "    iter = 0\n",
    "    for item in O:\n",
    "        if item[1] == i:\n",
    "            iter += 1\n",
    "    return iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e96eff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLosingFrequency(O, i):\n",
    "    iter = 0\n",
    "    for item in O:\n",
    "        if item[2] == i:\n",
    "            iter += 1\n",
    "    return iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae31b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Tu(c, graph, num_users, num_movies):\n",
    "    user_nodes = {node for node, data in graph.nodes(data=True) if data['bipartite'] == 0}\n",
    "    Tu = np.zeros((num_users, num_movies))\n",
    "    label = c\n",
    "    du = {}\n",
    "    # Loop over each user node\n",
    "    for id, user in enumerate(user_nodes):\n",
    "        user_edge_counts = 0\n",
    "        neighbors = set()\n",
    "        # Iterate over neighbors\n",
    "        for neighbor in graph.neighbors(user):\n",
    "            # Get the edge label\n",
    "            edge_label = graph[user][neighbor]['label']\n",
    "            neighbors.add(neighbor)\n",
    "            # Check if the edge label matches the specified label\n",
    "            if edge_label == label:\n",
    "                user_edge_counts += 1\n",
    "        \n",
    "        # Calculate du for the user node\n",
    "        du[id] = (1/user_edge_counts) if user_edge_counts != 0 else 0\n",
    "        \n",
    "        i = int(user) - 1\n",
    "        for j, neighbor in enumerate(neighbors):\n",
    "            Tu[i, j-1] = du[id]\n",
    "            \n",
    "    return Tu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71249d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Ti(c, graph, num_users, num_movies):\n",
    "    item_nodes = {node for node, data in graph.nodes(data=True) if data['bipartite'] == 1}\n",
    "    Ti = np.zeros((num_movies, num_users))\n",
    "    label = c\n",
    "    node_degrees = dict(nx.degree(graph))\n",
    "        # Loop over each user node\n",
    "    for item in item_nodes:\n",
    "        di = 1/node_degrees[item] if node_degrees[item] != 0 else 0\n",
    "            \n",
    "        # Iterate over neighbors\n",
    "        for neighbor in graph.neighbors(item):\n",
    "            # Get the edge label\n",
    "            edge_label = graph[item][neighbor]['label']\n",
    "            if edge_label == label:\n",
    "                i = item - 1\n",
    "                j = int(neighbor) -1\n",
    "                Ti[i, j] = di\n",
    "    return Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d2c571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_score_vectors(n, m):\n",
    "    # Generate random vector for Mi\n",
    "    Mi = np.random.rand(m, 1)\n",
    "    Mi /= np.sum(Mi)  # Normalize to ensure sum equals 1\n",
    "\n",
    "    # Generate random vectors for Mu for each labels\n",
    "    Mu = {}\n",
    "    sum_mu_vectors = np.zeros((n, 1))\n",
    "    for label in range(1, m):\n",
    "        Mu[label] = np.random.rand(n, 1)\n",
    "        Mu[label] /= np.sum(Mu[label])  # Normalize to ensure sum equals 1\n",
    "        sum_mu_vectors = sum_mu_vectors + Mu[label]\n",
    "\n",
    "    # Sumation of all Mu vectors\n",
    "    sum_of_values = np.sum(sum_mu_vectors) + np.sum(Mi)\n",
    "\n",
    "    #Normalize Mu and Mi vectors \n",
    "    Mi /= sum_of_values\n",
    "    for label in Mu:\n",
    "        Mu[label] /= sum_of_values\n",
    "        \n",
    "    return Mi, Mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff3f589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_labels(graph):\n",
    "    # Initialize an empty set to store edge labels\n",
    "    edge_labels = set()\n",
    "\n",
    "    # Iterate over the edges and collect labels\n",
    "    for u, v, data in graph.edges(data=True):\n",
    "        edge_labels.add(data['label'])\n",
    "        \n",
    "    return edge_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d851f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MemoRank(Tuc, Tic, R_, m, n, graph_labels):\n",
    "    alpha = 0.85\n",
    "    # Ensure that R sum up to 1 \n",
    "    sum_Rw = sum(R_)\n",
    "    R_ = [element / sum_Rw for element in R_]\n",
    "    R_ = np.array(R_)\n",
    "    #initialize Mi and Mu for each label\n",
    "    Mi, Mu = init_score_vectors(n, m)\n",
    "    Mu_new = {}\n",
    "    Mi_new = np.zeros((m, 1))\n",
    "    converge = False\n",
    "    convergence_threshold = 1e-6\n",
    "    t = 0\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "    while not converge:\n",
    "        print(\"iteration: \", t, \"***************************************\")\n",
    "        for c in graph_labels:\n",
    "            Mu_new[c] = alpha * np.dot(Tic[c].T, Mi)\n",
    "            Mi_new = Mi_new + np.dot(Tuc[c].T, Mu[c])\n",
    "            \n",
    "        \n",
    "        print(\"calculating scores for each label done after : \",  time.time() - start_time)   \n",
    "        # Update Mi for item score in this iteration\n",
    "        Mi_new = (Mi_new * alpha) + (R_ * (1-alpha))\n",
    "        #check if Mi converge to a stationary distribution\n",
    "        if np.linalg.norm(Mi - Mi_new) < convergence_threshold:\n",
    "            converge = True\n",
    "        elif t == 5:\n",
    "            converge =True\n",
    "        else:\n",
    "            Mi = Mi_new\n",
    "            Mu = Mu_new\n",
    "            t += 1\n",
    "            \n",
    "    return Mi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e91e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreNIt_recommendation(m, n, user_pairwise_set, user_item, win_or_lose, Tuc, Tic, graph_labels):\n",
    "    #Number of users: n And number of items: m\n",
    "    #initializing R vectors : initial probability\n",
    "    R_ = np.zeros((m, 1))\n",
    "    \n",
    "    for i in user_item[0]:\n",
    "        if (win_or_lose == 'win'):\n",
    "            R_[i] = calculateWinningFrequency(user_pairwise_set, i)\n",
    "        if (win_or_lose == 'lose'):\n",
    "            R_[i] = calculateLosingFrequency(user_pairwise_set, i)\n",
    "            \n",
    "    S = MemoRank(Tuc, Tic, R_, m, n, graph_labels)\n",
    "    \n",
    "    return S\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7246d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_user_nodes = {node for node, data in WNet.nodes(data=True) if data['bipartite'] == 0}\n",
    "W_movie_nodes = {node for node, data in WNet.nodes(data=True) if data['bipartite'] == 1}\n",
    "L_user_nodes = {node for node, data in LNet.nodes(data=True) if data['bipartite'] == 0}\n",
    "L_movie_nodes = {node for node, data in LNet.nodes(data=True) if data['bipartite'] == 1}\n",
    "\n",
    "print(\"Number of user nodes in Wnet graph: \", len(W_user_nodes))\n",
    "print(\"Number of user nodes in LNet graph: \", len(L_user_nodes))\n",
    "print(\"Number of Movie nodes in Wnet graph: \", len(W_movie_nodes))\n",
    "print(\"Number of user nodes in LNet graph: \", len(L_movie_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a1ea8",
   "metadata": {},
   "source": [
    "# Train and Test on users\n",
    "to evaluate the recomendation for users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e41343",
   "metadata": {},
   "source": [
    "### Calculate Transition matrix for Wnet -> Network for winning items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "030fef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get graph labels for Wnet and LNet graphs\n",
    "w_labels = get_graph_labels(WNet)\n",
    "l_labels = get_graph_labels(LNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84784926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transition matrix list \n",
    "Tuc = {}\n",
    "Tic = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba286a",
   "metadata": {},
   "source": [
    "For user with id = 1 Create a recommendation on training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b6d67",
   "metadata": {},
   "source": [
    "Calculate transition matrices for WNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6e2cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,num_movies):\n",
    "    Tic[c] = generate_Ti(c, WNet, num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c13bcec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,num_movies):\n",
    "    Tuc[c] = generate_Tu(c, WNet, num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train for Wnet and caculate item scores for user with id = 1\n",
    "Sw = PreNIt_recommendation(num_movies, num_users, pu[1], Wu[1], 'win', Tuc, Tic, w_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fe4fb",
   "metadata": {},
   "source": [
    "Calculate transition matrices for LNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42606ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,num_movies):\n",
    "    Tic[c] = generate_Ti(c, LNet, num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a671e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,num_movies):\n",
    "    Tuc[c] = generate_Tu(c, LNet, num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train for LNet and caculate item scores for user with id = 1\n",
    "SL = PreNIt_recommendation(num_movies, num_users, pu[1], Lu[1], 'lose', Tuc, Tic, l_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5107a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate total score for items\n",
    "S = Sw - SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a19736fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 7, 4, 17, 5, 6, 14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "# Get top ten movie recomendation (movie id) for user id = 1\n",
    "S_dict = {index: value for index, value in enumerate(S)}\n",
    "# Sort the dictionary based on values\n",
    "sorted_dict = dict(sorted(S_dict.items(), key=lambda item: item[1]))\n",
    "# Get top ten elements\n",
    "top_ten_elements = dict(list(sorted_dict.items())[-10:])\n",
    "# Get all IDs from the top ten dictionary\n",
    "top_ten_ids = list(top_ten_elements.keys())\n",
    "\n",
    "print(top_ten_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
